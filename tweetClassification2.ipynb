{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fQihdFc68Dx"
   },
   "source": [
    "# Disaster Tweet Classification #2\n",
    "\n",
    "This notebook consists of TFIDF vectorization and modelling and tuning of the TFIDF models.\n",
    "\n",
    "The BERT model is a complex model and consists of specific preprocessing and setting. The training time of the model was over 2 hours.\n",
    "\n",
    "I didnt want to tamper with the results of the model at any cost.\n",
    "Therefore, this separate notebook is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "id": "ClEiXpsp5kda",
    "outputId": "64299588-4811-4336-f24b-c69b5b81c9b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from statistics import *\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "import textstat\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import folium \n",
    "from folium import plugins \n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmGYWDrH7RAh"
   },
   "source": [
    "#### 1. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRqdzsua7bFp"
   },
   "outputs": [],
   "source": [
    "\n",
    "#utility functions:\n",
    "def plot_readability(a,b,title,bins=0.1,colors=['#3A4750', '#F64E8B']):\n",
    "  trace1 = ff.create_distplot([a,b], [\" Real disaster tweets\",\"Not real disaster tweets\"], bin_size=bins, colors=colors, show_rug=False)\n",
    "  \n",
    "  trace1['layout'].update(title=title)\n",
    "  py.iplot(trace1, filename='Distplot')\n",
    "  table_data= [[\"Statistical Measures\",\" Not real disaster tweets\",\"real disaster tweets\"], [\"Mean\",mean(a),mean(b)], [\"Standard Deviation\",pstdev(a),pstdev(b)],\n",
    "               [\"Variance\",pvariance(a),pvariance(b)],\n",
    "               [\"Median\",median(a),median(b)],\n",
    "               [\"Maximum value\",max(a),max(b)],\n",
    "               [\"Minimum value\",min(a),min(b)]]\n",
    "  trace2 = ff.create_table(table_data)\n",
    "  py.iplot(trace2, filename='Table')\n",
    "\n",
    "punctuations = string.punctuation\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "parser = English()\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    mytokens = \" \".join([i for i in mytokens])\n",
    "    return mytokens\n",
    "\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "def removeurl(raw_text):\n",
    "  clean_text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', raw_text, flags=re.MULTILINE)\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11jXefkt7z03"
   },
   "source": [
    "### 2. Import Data\n",
    "\n",
    "We work on the preprocessed data that we had created previously while working on the BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHPLZCMp7wS5"
   },
   "outputs": [],
   "source": [
    "# Importing cleaned data\n",
    "train_df = pd.read_csv('data/preprocessed_train.csv')\n",
    "test_df = pd.read_csv('data/preprocessed_test.csv')\n",
    "sub_df = pd.read_csv('data/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "VPNiR28l9asc",
    "outputId": "9d2043cf-a99c-44f9-afb0-ea260f44a9bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>target_relabeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this  # earthquake...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Forest fire near La Ronge Sask .  Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>All residents asked to  ' shelter in place '  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13,000 people receive  # wildfires evacuation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Just got sent this photo from Ruby  # Alaska a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id     keyword     location  \\\n",
       "0           0   1  no_keyword  no_location   \n",
       "1           1   4  no_keyword  no_location   \n",
       "2           2   5  no_keyword  no_location   \n",
       "3           3   6  no_keyword  no_location   \n",
       "4           4   7  no_keyword  no_location   \n",
       "\n",
       "                                                text  target  word_count  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1          13   \n",
       "1             Forest fire near La Ronge Sask. Canada       1           7   \n",
       "2  All residents asked to 'shelter in place' are ...       1          22   \n",
       "3  13,000 people receive #wildfires evacuation or...       1           8   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1          16   \n",
       "\n",
       "   unique_word_count  stopword_count  url_count  mean_word_length  char_count  \\\n",
       "0                 13               5          0          4.384615          69   \n",
       "1                  7               0          0          4.571429          38   \n",
       "2                 20               9          0          5.090909         133   \n",
       "3                  8               1          0          7.125000          65   \n",
       "4                 15               6          0          4.500000          88   \n",
       "\n",
       "   punctuation_count  hashtag_count  mention_count  \\\n",
       "0                  1              1              0   \n",
       "1                  1              0              0   \n",
       "2                  3              0              0   \n",
       "3                  2              1              0   \n",
       "4                  2              2              0   \n",
       "\n",
       "                                        text_cleaned  target_relabeled  \n",
       "0  Our Deeds are the Reason of this  # earthquake...                 1  \n",
       "1           Forest fire near La Ronge Sask .  Canada                 1  \n",
       "2  All residents asked to  ' shelter in place '  ...                 1  \n",
       "3  13,000 people receive  # wildfires evacuation ...                 1  \n",
       "4  Just got sent this photo from Ruby  # Alaska a...                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aN6xmfkPG0DR"
   },
   "source": [
    "#### 3. TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08U9e5xmG5mL"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vec.fit_transform(train_df['text_cleaned'].values.tolist() + test_df['text_cleaned'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text_cleaned'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['text_cleaned'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ag-guK3TxG0Z",
    "outputId": "31fc112c-714a-4e23-b0c0-c9ade65e6f17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x139122 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 174644 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y90Hdk9-HcI3"
   },
   "source": [
    "#### 4. Building Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-hJCfo2HhTM"
   },
   "source": [
    "##### 4.1 Generic Classification with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WBkv1vmW8Jzw"
   },
   "source": [
    "##### 4.1.1 Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWIMAm5DmRwg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getClassifierObj(classifier, rs):\n",
    "    '''Functio to get the classifier object\n",
    "    '''\n",
    "    if classifier == 'XGBoost':\n",
    "        from xgboost import XGBClassifier\n",
    "        classifier = XGBClassifier()\n",
    "    \n",
    "    elif classifier == 'LogisticRegression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = rs)\n",
    "    \n",
    "    elif classifier == 'KNN':\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    \n",
    "    elif classifier == 'SVM':\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = rs)\n",
    "        \n",
    "    elif classifier == 'Kernel SVM':\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = rs)\n",
    "        \n",
    "    elif classifier == 'NB':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        \n",
    "    elif classifier == 'DecisionTree':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = rs)\n",
    "        \n",
    "    elif classifier == 'RandomForest':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = rs)\n",
    "        \n",
    "    return classifier\n",
    "            \n",
    "def fitAndPredict(estimator,X_train,y_train,X_test):\n",
    "    '''Function to fit and predict\n",
    "    '''\n",
    "    estimator.fit(X_train,y_train)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def getModelAccuracy(y_test, y_pred):\n",
    "    '''Function to get model accuracy'''\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "def getFinalPredictions(classifiers, X_train,X_test, y_train, y_test):\n",
    "    ''' Function to get classifier with highest accuracy on the data\n",
    "    '''\n",
    "    # classifiers = ['LogisticRegression','KNN', 'Kernel SVM','DecisionTree','RandomForest','XGBoost']\n",
    "    # classifiers = ['RandomForest']\n",
    "    accuracy = 0\n",
    "    best_predictions = ''\n",
    "    bestClassifierName = ''\n",
    "    classifier = ''\n",
    "    \n",
    "    for classifierName in classifiers:\n",
    "        print('Evaluation started for ', classifierName)\n",
    "        classifier = getClassifierObj(classifierName,8)\n",
    "        y_pred = fitAndPredict(classifier,X_train,y_train,X_test)\n",
    "        \n",
    "        classifierAccuracy = getModelAccuracy(y_test,y_pred)\n",
    "        print('Average accuracy of {} is {:.2f}%'.format(classifierName,classifierAccuracy))\n",
    "        if classifierAccuracy > accuracy :\n",
    "            accuracy = classifierAccuracy\n",
    "            bestClassifierName = classifierName\n",
    "            best_predictions = y_pred\n",
    "            bestClassifier = classifier\n",
    "            \n",
    "            \n",
    "    print('Classifier with highest accuracy is {}'.format(bestClassifierName))\n",
    "    return best_predictions, accuracy, classifier      \n",
    "\n",
    "def classify(classifiers, X_train,X_test, y_train, y_test):\n",
    "    final_pred, final_accuracy, classifier = getFinalPredictions(classifiers, X_train,X_test, y_train, y_test)        \n",
    "    cm = confusion_matrix(y_test, final_pred)\n",
    "    print(cm)\n",
    "    return final_pred, final_accuracy, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "736k7kt_8PSv"
   },
   "source": [
    "##### 4.1.2 Classification using default parameters for the following classifiers:-\n",
    "\n",
    "1.   LogisticRegression\n",
    "2.   KNN\n",
    "3.   Kernel SVM\n",
    "4.   Random Forest\n",
    "5.   XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "QebVn5tvxtyG",
    "outputId": "6fc9c81a-891e-44c4-88dd-f5e0fced3837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation started for  LogisticRegression\n",
      "Average accuracy of LogisticRegression is 74.85%\n",
      "Evaluation started for  KNN\n",
      "Average accuracy of KNN is 75.71%\n",
      "Evaluation started for  Kernel SVM\n",
      "Average accuracy of Kernel SVM is 73.08%\n",
      "Evaluation started for  DecisionTree\n",
      "Average accuracy of DecisionTree is 73.01%\n",
      "Evaluation started for  RandomForest\n",
      "Average accuracy of RandomForest is 75.77%\n",
      "Evaluation started for  XGBoost\n",
      "Average accuracy of XGBoost is 70.78%\n",
      "Classifier with highest accuracy is RandomForest\n",
      "[[812  49]\n",
      " [320 342]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classifiers = ['LogisticRegression','KNN', 'Kernel SVM','RandomForest','XGBoost']\n",
    "# classifiers = ['RandomForest']\n",
    "\n",
    "\n",
    "train_y = train_df.target_relabeled.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, random_state=8, test_size = 0.2)\n",
    "final_pred, final_accuracy, bestClassifier = classify(classifiers,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "mGmlxKT769tC",
    "outputId": "b109305a-51cc-4c5b-8c45-64edc051301d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation started for  RandomForest\n",
      "Average accuracy of RandomForest is 76.43%\n",
      "Classifier with highest accuracy is RandomForest\n",
      "[[818  43]\n",
      " [316 346]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# classifiers = ['LogisticRegression','KNN', 'Kernel SVM','DecisionTree','RandomForest','XGBoost']\n",
    "classifiers = ['RandomForest']\n",
    "\n",
    "train_y = train_df.target_relabeled.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, random_state=8, test_size = 0.2)\n",
    "final_pred, final_accuracy, bestClassifier = classify(classifiers,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaU5dy2edUrn"
   },
   "source": [
    "#### 4.2 Tuning of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwECjWqN80EU"
   },
   "source": [
    "##### 4.2.1 Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "nUDLqRvK84vh",
    "outputId": "862e72ff-c02f-4e54-eae3-b0092ceb16bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 76.58%\n",
      "Best Parameters: {'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators' : list(range(100,300,50))}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print('Best Accuracy: {:.2f}%'.format(best_accuracy*100))\n",
    "print('Best Parameters:', best_parameters)\n",
    "# train_scoreNum, test_scoreNum = validation_curve(RandomForestClassifier(),\n",
    "#                                 X = X_train, y = y_train, \n",
    "#                                 param_name = 'n_estimators', \n",
    "#                                 param_range = num_est, cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4dxCRD19ATU"
   },
   "source": [
    "##### 4.2.2 Kernel SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0xoT4xe2HSJ-",
    "outputId": "6d7eb86e-b14d-4a1e-a752-8d2ca1d42c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 79.59%\n",
      "Best Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "\n",
    "parameters = [{'C': [1, 10, 100], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100], 'kernel': ['rbf'], 'gamma': [0.1, 0.5, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print('Best Accuracy: {:.2f}%'.format(best_accuracy*100))\n",
    "print('Best Parameters:', best_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urboDyz19GGv"
   },
   "source": [
    "##### 4.2.3 K nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "E-3oR9XppzpR",
    "outputId": "53f04f7d-4cc5-4929-f027-cf3b41ea4c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 77.54%\n",
      "Best Parameters: {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 43}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "parameters = [{'n_neighbors' : list(range(5,50,2)),\n",
    "               'leaf_size': [30,35,40,45,50],\n",
    "               'metric': ['minkowski', 'euclidean']\n",
    "               }]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print('Best Accuracy: {:.2f}%'.format(best_accuracy*100))\n",
    "print('Best Parameters:', best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bvll8OJ9LgG"
   },
   "source": [
    "##### 4.2.4 Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9zUbID5lx_Lq",
    "outputId": "2f0ff64d-2ef9-4e8a-ef6d-68f49901e66f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 79.67%\n",
      "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "parameters = [{'C': [1, 10, 100,1000], \n",
    "               'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "               'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "               }]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print('Best Accuracy: {:.2f}%'.format(best_accuracy*100))\n",
    "print('Best Parameters:', best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1tgsRiU9Qyz"
   },
   "source": [
    "##### 4.2.5 XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "colab_type": "code",
    "id": "96-0CK-kH3Jg",
    "outputId": "0cd91f8f-038c-4d50-9acc-28bd4984b3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 26.0min finished\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:242: DeprecationWarning:\n",
      "\n",
      "The nthread parameter is deprecated as of version .6.Please use n_jobs instead.nthread is deprecated.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:249: DeprecationWarning:\n",
      "\n",
      "The silent parameter is deprecated.Please use verbosity instead.silent is depreated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 28 minutes and 0.62 seconds.\n",
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([164.6867017 , 234.52644324, 235.00639017, 177.8218534 ,\n",
      "       189.56150119]), 'std_fit_time': array([ 0.61276134,  0.45626824,  1.82746491,  2.45172681, 47.9650434 ]), 'mean_score_time': array([0.14637272, 0.1670723 , 0.18501226, 0.16493742, 0.13338113]), 'std_score_time': array([0.00312982, 0.00222792, 0.00682904, 0.00268828, 0.02753328]), 'param_subsample': masked_array(data=[1.0, 0.6, 0.8, 1.0, 0.8],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[5, 1, 5, 5, 1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 5, 5, 5, 4],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[5, 1.5, 1, 5, 1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 0.8, 0.8, 0.6, 1.0],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.74909028, 0.82208688, 0.76823985, 0.75869955, 0.81321541]), 'split1_test_score': array([0.76088119, 0.80898322, 0.77444684, 0.76915728, 0.80079492]), 'split2_test_score': array([0.76987651, 0.82835925, 0.78084996, 0.78396893, 0.81768787]), 'mean_test_score': array([0.75994933, 0.81980978, 0.77451222, 0.77060859, 0.81056607]), 'std_test_score': array([0.00851149, 0.00807244, 0.00514826, 0.0103671 , 0.00714643]), 'rank_test_score': array([5, 1, 3, 4, 2], dtype=int32)}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5,\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=None, n_estimators=600, n_jobs=1,\n",
      "              nthread=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=True, subsample=0.6, verbosity=1)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 5 parameter combinations:\n",
      "0.6396195619527443\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def timer(start_time=None):\n",
    "  if not start_time:\n",
    "    start_time = datetime.now()\n",
    "    return start_time\n",
    "  elif start_time:\n",
    "    thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "    tmin, tsec = divmod(temp_sec, 60)\n",
    "    print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "params = {'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        \n",
    "        }\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable \n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meXelvPjvJWg"
   },
   "source": [
    "#### 4.2 Reclassify using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RDiK6SIvzAD"
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "final_classifier = LogisticRegression(C =100, penalty ='l1', solver= 'saga')\n",
    "final_classifier.fit(X_train,y_train)\n",
    "final_pred = final_classifier.predict(test_tfidf)\n",
    "sub_df['target'] = final_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Hd_JXVWEwmS"
   },
   "outputs": [],
   "source": [
    "\n",
    "# KNN\n",
    "final_knn_classifier = KNeighborsClassifier(leaf_size= 30, metric= 'minkowski', n_neighbors= 43)\n",
    "final_knn_classifier.fit(X_train,y_train)\n",
    "final_knn_pred = final_knn_classifier.predict(test_tfidf)\n",
    "sub_df['target'] = final_knn_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGUkF9Pcjqc3"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "final_rf_classifier = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 8)\n",
    "final_rf_classifier.fit(X_train,y_train)\n",
    "final_rf_pred = final_rf_classifier.predict(test_tfidf)\n",
    "sub_df['target'] = final_rf_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X59XKC6R9q2T"
   },
   "outputs": [],
   "source": [
    "# Kernel SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "final_svm_classifier = SVC(C = 10, gamma = 0.1, kernel = 'rbf')\n",
    "final_svm_classifier.fit(X_train,y_train)\n",
    "final_svm_pred = final_svm_classifier.predict(test_tfidf)\n",
    "sub_df['target'] = final_svm_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "-UwuoShcFzD1",
    "outputId": "d82bda55-e737-4480-f1fb-80cdc9b17986"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:242: DeprecationWarning:\n",
      "\n",
      "The nthread parameter is deprecated as of version .6.Please use n_jobs instead.nthread is deprecated.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:249: DeprecationWarning:\n",
      "\n",
      "The silent parameter is deprecated.Please use verbosity instead.silent is depreated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "\n",
    "final_xgb_classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5,\n",
    "              learning_rate=0.02, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing=None, n_estimators=600, n_jobs=1,\n",
    "              nthread=1, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=True, subsample=0.6, verbosity=1)\n",
    "\n",
    "final_xgb_classifier.fit(X_train,y_train)\n",
    "final_xgb_pred = final_xgb_classifier.predict(test_tfidf)\n",
    "sub_df['target'] = final_xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnGMZRj9v8sQ"
   },
   "outputs": [],
   "source": [
    "# Export the files and submit one by one\n",
    "import csv\n",
    "sub_df.to_csv('submission_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUsUJFaF9ll8"
   },
   "source": [
    "## 5. Results\n",
    "\n",
    "|Classifier           | Accuracy |\n",
    "|---------------------|----------|\n",
    "|Random Forest        | 77.51%   |\n",
    "|KNN                  | 77.11%   |\n",
    "|Logistic Regression  | 79.93%   |\n",
    "|Kernel   SVM         | 79.99%   |\n",
    "|XGBoost              | 73.95%   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQ1xh6Ro_Ydi"
   },
   "source": [
    "### Kernel SVM achieved the best score of 79.99% after submission in Kaggle Competition."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tweetClassification2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
